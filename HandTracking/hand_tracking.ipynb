{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf3abb3-44e6-43e3-bf3e-33e44817db6b",
   "metadata": {},
   "source": [
    "## Hand Tracking Project\n",
    "\n",
    "We will be using the **openCV** and **MediaPipe** for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde7563-8c5e-44f6-9c9c-47a2c32b6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first the imports\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86ba06-ebc8-4e3d-a515-6915063f5f5e",
   "metadata": {},
   "source": [
    "we need to start with capturing the video from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0eacc8-83b0-4f2e-b315-2ff0bcfa4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tracking the time\n",
    "past_time = 0\n",
    "curr_time = 0\n",
    "\n",
    "## capturing the webcam \n",
    "video = cv2.VideoCapture(0)\n",
    "## creating an instance of the mp hand\n",
    "## with the default values for now\n",
    "mphand = mp.solutions.hands\n",
    "hands = mphand.Hands()\n",
    "## we need the drawing from mp\n",
    "## to draw the points on the detected hands\n",
    "drawhands = mp.solutions.drawing_utils\n",
    "while True:\n",
    "    success, img = video.read()\n",
    "    ## we need to change the colors for the captured video\n",
    "    rbg_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ## and then process the info\n",
    "    results = hands.process(rbg_img)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand in results.multi_hand_landmarks:\n",
    "            drawhands.draw_landmarks(img, hand, mphand.HAND_CONNECTIONS)\n",
    "            for id, lm in enumerate(hand.landmark):\n",
    "                ## since the locations are not in pixels\n",
    "                ## we need to convert them \n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                print(id, cx, cy)\n",
    "    ## calculating the fps\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - past_time)\n",
    "    past_time = curr_time\n",
    "    ## and the adding it to the image\n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_COMPLEX_SMALL,3,\n",
    "                color=(0, 0, 0), thickness=1)\n",
    "    \n",
    "    ## showing the captured video\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195aaf76-d5d0-435f-b848-716abd60a3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf5ee2-2d2d-4468-b528-e7eebb2e94a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
